# HumanUploader
The Human Uploader 1.0 and Unggah Saya 1.0 are Python scripts that use the OpenAI API to generate random questions related to human personality for the user to answer, and puts the results into files that can be used to train LLMs. With enough time and questions, this uploads the user. Questions can be drawn from the Myers-Briggs Personality Index or other related topics. The scripts ensure that chronologically-close questions are related to each other and that no questions are repeated. The questions and answers are logged into a series of text files named with the current date.

## Requirements
- Python 3
- OpenAI Python package
- An OpenAI API key
- Installation
- Install the OpenAI package if you haven't already:

```
pip3 install openai
```

## Usage
### For English version (humanuploader.py)

- Copy the contents of the human_uploader.py script provided above into a new file with the same name.

- Replace "your_openai_api_key" in the script with your actual OpenAI API key.

- Run the script:

```
python3 humanuploader.py
```

### For Indonesian version (unggahsaya.py)
- Copy the contents of the Indonesian version of the human_uploader.py script provided above into a new file named unggahsaya.py.

- Replace "your_openai_api_key" in the script with your actual OpenAI API key.

- Run the script:

```
python3 unggahsaya.py
```

Both scripts will generate random questions related to human personality using the OpenAI API. The questions will be asked one by one, and the user will input their answers. The questions and answers will be logged into a text file with the current date in the "output" directory. The main difference between the two scripts is the language used: the Human Uploader 1.0 uses English, while Unggah Saya 1.0 uses Indonesian.

The resulting text files generated by the Human Uploader 1.0 or Unggah Saya 1.0 scripts can be used as valuable training data for large language models such as HuggingFace GPT-2, DialoGPT, or BlenderBot. These text files contain real-life questions and answers based on the human's personality.

Result: The human's mental model is approximated in the LLM's human-like responses. 

To use the text files for training, you would need to preprocess the data into a format compatible with the respective model and training framework. This may involve tokenizing the text, splitting it into training and validation sets, and converting it into a suitable format such as PyTorch tensors. Once the data is prepared, you can fine-tune the pretrained models using the HuggingFace Transformers library or other relevant frameworks with your custom dataset, enhancing the model's capability to generate more accurate and contextually relevant responses in the domain of human personality.

# Important Note
Running these scripts might consume a significant amount of your OpenAI API tokens, and you may need to monitor your usage to prevent unexpected costs.
